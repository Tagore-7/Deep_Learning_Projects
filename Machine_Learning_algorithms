# -*- coding: utf-8 -*-
"""Machine_Learning_Algorithms.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tFJLWzI_BXi2ckOWcZ235fJwLv4QoP5G
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import scale

from sklearn import datasets

iris = datasets.load_iris()

iris.data.shape

iris.feature_names

X = scale(iris.data)

X

iris.target

clustering =  KMeans(n_clusters = 3, random_state=1)

clustering.fit(X)

clustering.labels_

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

iris_df = pd.DataFrame(iris.data)

iris_df.head()

iris_df.columns = ['sepal_length','sepeal_width','petal_length','petal_width']

iris_df.head()

y = pd.DataFrame(iris.target)
y.columns = ['targets']

y.head()

import numpy as np
colors = np.array(['red','yellow','black'])

plt.scatter(x = iris_df.petal_length, y = iris_df.petal_width, c = colors[iris.target])

plt.scatter(x = iris_df.petal_length, y = iris_df.petal_width, c =colors[clustering.labels_] )

import sklearn

from sklearn.tree import DecisionTreeClassifier

import pandas as pd

from sklearn.tree import export_graphviz

from IPython.display import Image

import pydotplus

from sklearn.datasets import load_iris

iris = load_iris()

iris.data

X, y = iris.data, iris.target

model = DecisionTreeClassifier()

clf = model.fit(X,y)

from sklearn import tree

tree.plot_tree(clf)

dot_data = tree.export_graphviz(clf,out_file= None, feature_names= iris.feature_names, class_names=iris.target_names,filled = True, rounded = True, special_characters= True)

import graphviz

graph = graphviz.Source(dot_data)
graph

from sklearn.decomposition import PCA

import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

model_pca = PCA()

iris_pca = model_pca.fit_transform(X)

iris_pca

model_pca.explained_variance_ratio_

import pandas as pd
iris_df = pd.DataFrame(model_pca.explained_variance_ratio_)
iris_df.plot(kind = 'bar')

import pandas as pd
import sklearn

from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import train_test_split

from sklearn.metrics import confusion_matrix, accuracy_score

wine_df = pd.read_csv("/content/winequality-white.csv",delimiter= ';')

wine_df.head()

wine_df['taste'] = 'Good'

wine_df.head()

wine_df.loc[(wine_df.quality < 5),'taste'] = 'Bad'
wine_df.loc[(wine_df.quality > 7),'taste'] = 'Good'
wine_df.loc[(wine_df.quality > 5) & (wine_df.quality < 7),'taste'] = 'Normal'

wine_df.head()

model = RandomForestClassifier()

X = wine_df.iloc[:,:12]
X

y = wine_df.iloc[:,12]

y

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.3, random_state= 10)

model.fit(X_train,y_train)

y_predict = model.predict(X_test)

accuracy_score(y_test,y_predict)

confusion_matrix(y_test,y_predict)

# Artificial Neural Network

import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import classification_report,confusion_matrix, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler

breast_cancer = load_breast_cancer()

breast_cancer.keys

print(df.DESCR)

breast_cancer.data.shape

breast_cancer.feature_names

breast_cancer.target

breast_cancer.target_names

X = breast_cancer.data
y = breast_cancer.target

scalar = StandardScaler()

X = scalar.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state= 10)

model = MLPClassifier(hidden_layer_sizes= (100,100,100),batch_size=10)

model.fit(X_train, y_train )

y_predict = model.predict(X_test)

confusion_matrix(y_test, y_predict)

accuracy_score(y_test, y_predict)

print(classification_report(y_test, y_predict))

# Support vector machines

import pandas as pd

car_data = pd.read_csv('/content/car.data',sep=',')

car_data.head()

from sklearn.preprocessing import LabelEncoder
enc = LabelEncoder()
car_data.vhigh = enc.fit_transform(car_data.vhigh)
car_data['vhigh.1'] = enc.fit_transform(car_data['vhigh.1'])
car_data.small = enc.fit_transform(car_data.small)
car_data.low	 = enc.fit_transform(car_data.low)

car_data.head()

from sklearn.model_selection import train_test_split
X = car_data.iloc[:,:-1]
y = car_data.unacc

X_train, X_test, y_train, y_test = train_test_split(X , y , random_state = 10, test_size= 0.3)

from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

model = SVC()
X_train = X_train.replace('5more', '5.0')
X_train = X_train.replace('more', '5.0')
X_test = X_test.replace('5more', '5.0')
X_test = X_test.replace('more', '5.0')
model.fit(X_train, y_train)
y_predict = model.predict(X_test)

print(classification_report(y_test, y_predict))

confusion_matrix(y_test, y_predict)

accuracy_score(y_test, y_predict)

from sklearn.model_selection import GridSearchCV

parameters = {
    'kernel': ['rbf'],
    'C' : [1,10,100,500,1000,2000,1000000],
    'gamma' : [0.01,0.1,0.5,1.0]
}
model_grid = GridSearchCV(SVC(), param_grid= parameters)

model_grid.fit(X_train,y_train)

model.predict(X_test)

model_grid.best_score_

model_grid.best_params_

# XGBoost Algorithm

from xgboost import XGBClassifier

XGBClassifier()

import pandas as pd
from sklearn.datasets import load_breast_cancer
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns= data.feature_names)
X.head()

y = data.target
y

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,test_size=0.2)

model = XGBClassifier()
model.fit(X_train, y_train)
y_predict = model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

accuracy_score(y_test, y_predict)

print(classification_report(y_test, y_predict))

confusion_matrix(y_test, y_predict)

